<link rel="import" href="../../bower_components/polymer/polymer.html">
<link rel="import" href="../../bower_components/core-icons/av-icons.html">

<polymer-element name="ivx-qtype-usermedia" attributes="filter mode">
  <template>
    <!-- Media Encoder WebM -->
    <script src="../../bower_components/whammy/whammy.js"></script>

    <!-- Audio Recorder -->
    <script src="../../bower_components/Recorderjs/recorder.js"></script>

    <!-- Stylesheet -->
    <link rel="stylesheet" href="ivx-qtype-usermedia.css">

    <div vertical layout center>
      <div id="videoContainer">
        <template if="{{ _showLiveVideo }}">
          <!-- live camera -->
          <video id="liveVideo" class="{{ _filterSelected }}"></video>
        </template>

        <template if="{{ !_showLiveVideo }}">
          <!-- playback from existing video -->
          <video id="playbackVideo" class="{{ _filterSelected }}" controls loop autoplay="true"></video>
        </template>
      </div>

      <div id="buttonContainer" class="spaceToTop">
        <!-- First enable camera/mic to record anything -->
        <template if="{{ !_userAcceptedMediaAccess }}">
          <paper-button raised on-tap="{{ onEnableTapped }}">
            <core-icon icon="av:videocam"></core-icon>
            <div>Zugriff aktivieren</div>
          </paper-button>
        </template>

        <template if="{{ _userAcceptedMediaAccess }}">
          <div center layout horizontal>
            <div center layout vertical>
              <paper-button id="recordButton" raised on-tap="{{ onRecordingTapped }}">
                <core-icon icon="radio-button-off"></core-icon>
                <div>
                  <template if="{{ !_recordingNow }}">Aufnahme starten</template>
                  <template if="{{ _recordingNow }}">Aufnahme stoppen</template>
                </div>
              </paper-button>

              <paper-radio-group selected="{{ _filterSelected }}" class="spaceToTop">
                <template repeat="{{ filter, index in _filters }}">
                  <paper-radio-button
                    name="{{ filter }}"
                    label="{{ filter }}"
                    on-tap="{{ onFilterTapped }}">
                  </paper-radio-button>
                </template>
              </paper-radio-group>
            </div>
          </div>
        </template>
      </div>
      <div id="consoleContainer" class="spaceToTop"></div>
    </div>
  </template>

  <script>
    (function () {
      Polymer({
        _viewport: {
          x: 0,
          y: 0
        },

        _filters: ['Kein Filter', 'grayscale', 'sepia', 'invert', 'brightness', 'blur'],
        _filterSelected: 'Kein Filter',

        _userAcceptedMediaAccess: false,

        // *** video specific ***
        _showLiveVideo: true,
        _videoCanvas: document.createElement('canvas'), // offscreen canvas
        _videoFrames: [],

        // *** audio specific ***
        _audioRecorder: null,
        _audioContext: null,
        _realAudioInput: null,
        _inputPoint: null,

        // *** general ***
        _stream: {},
        _recordingNow: false,

        _consoleContainer: null,

        _startTime: null,
        _endTime: null,
        _totalDuration: null,

        _rafId: null,

        onRecordingTapped: function(event, detail, sender) {
          this._recordingNow = !this._recordingNow;

          // visual aspect
          this._changeUIState(sender.children[0]);

          // recording
          if (this._recordingNow) {
            this._startRecord();
          } else {
            this._stopRecord();
          }
        },

        _changeUIState: function(recordIcon) {
          recordIcon.icon = recordIcon.icon == 'radio-button-on' ? 'radio-button-off' : 'radio-button-on';
          recordIcon.className = recordIcon.className == 'pulsate' ? '' : 'pulsate';
        },

        _startRecord: function() {
          this._startRecordVideo();
          this._startRecordAudio();
        },

        _startRecordVideo: function() {
          this._videoFrames = [];
          this._consoleContainer = this.shadowRoot.querySelector('#consoleContainer');

          function drawVideoFrame_(time) {
            this._rafId = requestAnimationFrame((drawVideoFrame_).bind(this)); // cross browser safe!

            this._videoCanvas.getContext('2d').drawImage(this.$.liveVideo, 0, 0, this._videoCanvas.width, this._videoCanvas.height);

            this._consoleContainer.innerHTML = 'Recording... ' + Math.round((Date.now() - this._startTime) / 1000) + 's';

            // Read back canvas as webp.
            var url = this._videoCanvas.toDataURL('image/webp', 1); // image/jpeg is a way faster :(
            this._videoFrames.push(url);
          };

          this._startTime = Date.now();
          this._rafId = requestAnimationFrame((drawVideoFrame_).bind(this));
        },

        _startRecordAudio: function() {
          this._audioRecorder.clear();
          this._audioRecorder.record();
        },

        _stopRecord: function() {
          this._stopRecordVideo();
          this._stopRecordAudio();
        },

        _stopRecordVideo: function() {
          cancelAnimationFrame(this._rafId);
          this._endTime = Date.now();
          this._totalDuration = ((this._endTime - this._startTime) / 1000);

          this._consoleContainer.innerHTML = ('Frames captured: ' + this._videoFrames.length + ' => ' + this._totalDuration + 's Video');
          this._embedVideoPreview();
        },

        _stopRecordAudio: function() {
          this._audioRecorder.stop();
          this._audioRecorder.getBuffer(function(buffers) {
            // buffers is a two-dimensional stereo buffer
            var newSource = this._audioContext.createBufferSource();
            var newBuffer = this._audioContext.createBuffer(2, buffers[0].length, this._audioContext.sampleRate);
            newBuffer.getChannelData(0).set(buffers[0]);
            newBuffer.getChannelData(1).set(buffers[1]);
            newSource.buffer = newBuffer;

            newSource.connect(this._audioContext.destination);
            newSource.start(0);
          });

          // force download the wave
//          this._audioRecorder.exportWAV(function(audioBlob) {
//             Recorder.forceDownload(audioBlob, 'myRecordedAudio.wav');
//          });
        },

        _embedVideoPreview: function() {
          // switch from live to recorded video
          this._showLiveVideo = false;

          // binding is already applied in Polymer.job to 'this' context
          this.job('delayAbit', function() {
            var playbackVideo = this.shadowRoot.querySelector('#playbackVideo');
            playbackVideo.style.width = this._videoCanvas.width + 'px';
            playbackVideo.style.height = this._videoCanvas.height + 'px';

            // adjust the recorded frames to the duration, so we get the real speed!
            var fps = this._videoFrames.length / this._totalDuration;
            var webmBlob = Whammy.fromImageArray(this._videoFrames, fps);

            playbackVideo.src = window.URL.createObjectURL(webmBlob);
          });
        },

        attached: function() {
          this.job('delayAbit', function() {
            this._viewport.x = this.offsetWidth;
            this._viewport.y = this.offsetHeight;
          });
        },

        onEnableTapped: function() {
          this._initGetUserMedia();
        },

        onFilterTapped: function(event, detail, sender) {
          this._filterSelected = sender.getAttribute('name');
        },

        _initAudioContext: function() {
          window.AudioContext = window.AudioContext || window.webkitAudioContext;

          if (!window.AudioContext) {
            alert('AudioContext API is NOT supported in your browser :(');
            return;
          }

          this._audioContext = new AudioContext();

          // taken from http://www.webaudiodemos.appspot.com/AudioRecorder/js/main.js
          this._inputPoint = this._audioContext.createGain();

          // Create an AudioNode from the stream.
          this._realAudioInput = this._audioContext.createMediaStreamSource(this._stream);
          this._audioInput = this._realAudioInput;
          this._audioInput.connect(this._inputPoint);

          this._audioRecorder = new Recorder(this._inputPoint, {
            workerPath: '/bower_components/Recorderjs/recorderWorker.js'
          });

          var zeroGain = this._audioContext.createGain();
          zeroGain.gain.value = 0.0;
          this._inputPoint.connect(zeroGain);
          zeroGain.connect(this._audioContext.destination);
        },

        _initGetUserMedia: function() {
          var videoDim = {
            width: 640,
            height: 480
          };

          if (this._viewport.x < 640 + 320 || this._viewport.y < 480 + 240) {
            videoDim.width = 320;
            videoDim.height = 240;
          }

          this._videoCanvas.width = videoDim.width * 2;
          this._videoCanvas.height = videoDim.height * 2;

          navigator.getUserMedia = (
            navigator.getUserMedia ||
            navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia ||
            navigator.msGetUserMedia
          );

          if (navigator.getUserMedia) {
            // see https://developer.mozilla.org/en-US/docs/NavigatorUserMedia.getUserMedia
            navigator.getUserMedia (

              // constraints
              {
                video: {
                  mandatory: {
                    minWidth: videoDim.width,
                    minHeight: videoDim.height
                  }
                },
                audio: {
                  mandatory: {
                    googEchoCancellation: true,
                    googAutoGainControl: true,
                    googNoiseSuppression: true,
                    googHighpassFilter: false
                  },
                  optional: []
                }
              },

              // successCallback
              (function(stream) {
                this._stream = stream;
                this._userAcceptedMediaAccess = true;

                // show live video
                var video = this.$.liveVideo;
                video.src = window.URL.createObjectURL(this._stream);
                video.play();

                // init Audio
                this._initAudioContext();
              }).bind(this),

              // errorCallback
              function(err) {
                console.log("The following error occured: " + err);
              }
            );
          } else {
            alert('getUserMedia API is NOT supported in your browser :(');
          }
        }
      });

    })();
  </script>
</polymer-element>
