<link rel="import" href="../../bower_components/polymer/polymer.html">
<link rel="import" href="../../bower_components/core-icons/av-icons.html">

<polymer-element name="ivx-qtype-usermedia" attributes="filter mode">
  <template>
    <!-- Media Encoder WebM -->
    <script src="../../bower_components/whammy/whammy.js"></script>

    <!-- Audio Recorder -->
    <script src="../../bower_components/Recorderjs/recorder.js"></script>

    <!-- Stylesheet -->
    <link rel="stylesheet" href="ivx-qtype-usermedia.css">

    <div vertical layout center>
      <div id="videoContainer">
        <template if="{{ _currentUIState == 'deviceAccessGranted' }}">
          <!-- live camera -->
          <video id="liveVideo" class="{{ _filterSelected }}" muted></video>
        </template>

        <template if="{{ _currentUIState == 'playbackRecord' }}">
          <!-- playback from existing video -->
          <video id="playbackVideo" class="{{ _filterSelected }}" on-ended="{{ onPlaybackEnded }}" on-timeupdate="{{ onPlaybackTimeupdate }}"></video>
          <audio id="playbackAudio" volume="1.0" type="audio/wave"></audio>

          <!-- progress line -->
          <div id="progressLine"></div>
        </template>
      </div>

      <div id="buttonContainer" class="spaceToTop">
        <!-- First enable camera/mic to record anything -->
        <template if="{{ _currentUIState == 'waitingForDeviceAccess' }}">
          <paper-button raised on-tap="{{ onEnableTapped }}">
            <core-icon icon="av:videocam"></core-icon>
            <div>Zugriff aktivieren</div>
          </paper-button>
        </template>

        <template if="{{ _currentUIState == 'deviceAccessGranted' }}">
          <div center layout horizontal>
            <div center layout vertical>
              <paper-button id="recordButton" raised on-tap="{{ onRecordingTapped }}">

                <!-- glow/pulsate the record icon in recording mode -->
                <template if="{{ !_recordingNow }}">
                  <core-icon icon="radio-button-off"></core-icon>
                </template>

                <template if="{{ _recordingNow }}">
                  <core-icon icon="radio-button-on" class="pulsate"></core-icon>
                </template>

                <div>
                  <template if="{{ !_recordingNow }}">Aufnahme starten</template>
                  <template if="{{ _recordingNow }}">Aufnahme stoppen</template>
                </div>
              </paper-button>

              <paper-radio-group selected="{{ _filterSelected }}" class="spaceToTop">
                <template repeat="{{ filter, index in _filters }}">
                  <paper-radio-button
                    name="{{ filter }}"
                    label="{{ filter }}"
                    on-tap="{{ onFilterTapped }}">
                  </paper-radio-button>
                </template>
              </paper-radio-group>
            </div>
          </div>
        </template>

        <template if="{{ _currentUIState == 'playbackRecord' }}">
          <div center layout horizontal>

            <!-- play button -->
            <template if="{{ _playerMode == 'videoStopped' || _playerMode == 'videoPaused' }}">
              <paper-button id="playButton" raised on-tap="{{ onPlayTapped }}">
                <core-icon icon="av:play-arrow"></core-icon>
              </paper-button>
            </template>

            <!-- pause button -->
            <template if="{{ _playerMode == 'videoPlaying' }}">
              <paper-button id="pauseButton" raised on-tap="{{ onPauseTapped }}">
                <core-icon icon="av:pause"></core-icon>
              </paper-button>
            </template>

            <!-- stop button -->
            <paper-button id="stopButton" raised on-tap="{{ onStopTapped }}">
              <core-icon icon="av:stop"></core-icon>
            </paper-button>

            <!-- redo button -->
            <paper-button id="redoButton" raised on-tap="{{ onRedoTapped }}">
              <core-icon icon="av:replay"></core-icon>
              <div>Aufnahme wiederholen</div>
            </paper-button>
          </div>
        </template>
      </div>
      <div id="consoleContainer" class="spaceToTop"></div>
    </div>
  </template>

  <script>
    (function () {
      Polymer({
        _viewport: {
          width: 0,
          height: 0
        },

        _filters: ['Kein Filter', 'grayscale', 'sepia', 'invert', 'brightness', 'blur'],
        _filterSelected: 'Kein Filter',

        _uiStateEnum: {
          WAITING_FOR_DEVICE_ACCESS: 'waitingForDeviceAccess',
          DEVICE_ACCESS_GRANTED: 'deviceAccessGranted',
          PLAYBACK_RECORD: 'playbackRecord'
        },
        _currentUIState: '',
        _playerMode: 'videoStopped',

        // *** video specific ***
        _videoCanvas: document.createElement('canvas'), // offscreen canvas
        _videoFrames: [],
        _videoBlob: null,

        // *** audio specific ***
        _audioRecorder: null,
        _audioContext: null,
        _inputPoint: null,
        _audioBlob: null,

        // *** general ***
        _stream: {},

        _startTime: null,
        _endTime: null,
        _totalDuration: null,

        _rafId: null,

        ready: function() {
          this._currentUIState = this._uiStateEnum.WAITING_FOR_DEVICE_ACCESS;
        },

        _shortSelect: function(selector) {
          return this.shadowRoot.querySelector(selector);
        },

        onRecordingTapped: function(event, detail, sender) {
          this._recordingNow = !this._recordingNow;


          /* visual aspect
          var recordIcon = sender.children[0];
          recordIcon.icon = recordIcon.icon == 'radio-button-on' ? 'radio-button-off' : 'radio-button-on';
          recordIcon.className = recordIcon.className == 'pulsate' ? '' : 'pulsate';
*/
          // recording
          if (this._recordingNow) {
            this._startRecord();
          } else {
            this._stopRecord();
          }
        },

        _startRecord: function() {
          this._startRecordVideo();
          this._startRecordAudio();
        },

        _startRecordVideo: function() {
          this._videoBlob = null; // reset blob
          this._videoFrames = [];

          // clear the canvas first (optional)
          this._videoCanvas.getContext('2d').clearRect(0, 0, this._videoCanvas.width, this._videoCanvas.height);

          function drawVideoFrame_(time) {
            this._rafId = requestAnimationFrame((drawVideoFrame_).bind(this)); // cross browser safe!

            this._videoCanvas.getContext('2d').drawImage(this._shortSelect('#liveVideo'), 0, 0, this._videoCanvas.width, this._videoCanvas.height);

            this._shortSelect('#consoleContainer').innerHTML = 'Recording... ' + Math.round((Date.now() - this._startTime) / 1000) + 's';

            // Read back canvas as webp.
            var url = this._videoCanvas.toDataURL('image/webp', 1); // image/jpeg is a way faster :(
            this._videoFrames.push(url);
          };

          this._startTime = Date.now();
          this._rafId = requestAnimationFrame((drawVideoFrame_).bind(this));
        },

        _startRecordAudio: function() {
          this._audioBlob = null; // reset blob

          this._audioRecorder.clear();
          this._audioRecorder.record();
        },

        _stopRecord: function() {
          // switch from live to recorded video
          this._currentUIState = this._uiStateEnum.PLAYBACK_RECORD;
          this._playerMode = 'videoStopped';

          this._stopRecordVideo();
          this._stopRecordAudio((function() {
            this._embedVideoAudioPreview();
          }).bind(this));
        },

        _stopRecordVideo: function() {
          cancelAnimationFrame(this._rafId);
          this._endTime = Date.now();
          this._totalDuration = ((this._endTime - this._startTime) / 1000);

          // adjust the recorded frames to the duration, so we get the real speed!
          var fps = this._videoFrames.length / this._totalDuration;
          this._videoBlob = Whammy.fromImageArray(this._videoFrames, fps);

          this._shortSelect('#consoleContainer').innerHTML = ('Frames captured: ' + this._videoFrames.length + ', ' +
                                                this._totalDuration + 's Video (~' + Math.floor(fps) + 'fps)');
        },

        _stopRecordAudio: function(callbackExportDone) {
          this._audioRecorder.stop();

          // just play audio direct via the audioContext API
          /*
          this._audioRecorder.getBuffer((function(buffers) {
            // buffers is a two-dimensional stereo buffer
            var newSource = this._audioContext.createBufferSource();
            var newBuffer = this._audioContext.createBuffer(2, buffers[0].length, this._audioContext.sampleRate);
            newBuffer.getChannelData(0).set(buffers[0]);
            newBuffer.getChannelData(1).set(buffers[1]);

            newSource.buffer = newBuffer;
            newSource.connect(this._audioContext.destination);
            newSource.start(0);
          }).bind(this));
          */

          this._audioRecorder.exportWAV((function(audioBlob) {
            // Recorder.forceDownload(audioBlob, 'myRecordedAudio.wav');
            this._audioBlob = audioBlob;
            callbackExportDone();
          }).bind(this));
        },

        _embedVideoAudioPreview: function() {
          // delay a bit to catch the DOM changed ...
          this.job('delayAbit', function() {
            // binding is already applied in Polymer.job to 'this' context
            var playbackVideo = this._shortSelect('#playbackVideo');
            var playbackAudio = this._shortSelect('#playbackAudio');

            // adjust size of player to video size
            playbackVideo.style.width = this._videoCanvas.width + 'px';
            playbackVideo.style.height = this._videoCanvas.height + 'px';

            // add blob to src of video/audio elements
            playbackVideo.src = window.URL.createObjectURL(this._videoBlob);
            playbackAudio.src = window.URL.createObjectURL(this._audioBlob);
          });
        },

        attached: function() {
          this.job('delayAbit', function() {
            this._viewport.width = this.offsetWidth;
            this._viewport.height = this.offsetHeight;
          });
        },

        onEnableTapped: function(event, detail, sender) {
          this._initGetUserMedia();
        },

        onFilterTapped: function(event, detail, sender) {
          this._filterSelected = sender.getAttribute('name');
        },

        onPlaybackEnded: function(event, detail, sender) {
          this._playerMode = 'videoStopped';
          this._shortSelect('#progressLine').style.width = '100%';
        },

        onPlaybackTimeupdate: function(event, detail, sender) {
          var percentPlayed = (sender.currentTime / this._totalDuration) * 100;
          this._shortSelect('#progressLine').style.width = percentPlayed + '%';
        },

        onPlayTapped: function(event, detail, sender) {
          this._playerMode = 'videoPlaying';

          this._shortSelect('#playbackVideo').play();
          this._shortSelect('#playbackAudio').play();
        },

        onPauseTapped: function(event, detail, sender) {
          this._playerMode = 'videoPaused';

          this._shortSelect('#playbackVideo').pause();
          this._shortSelect('#playbackAudio').pause();
        },

        onStopTapped: function(event, detail, sender) {
          this._playerMode = 'videoStopped';

          this._shortSelect('#playbackVideo').load();
          this._shortSelect('#playbackAudio').load();
        },

        onRedoTapped: function(event, detail, sender) {
          this._currentUIState = this._uiStateEnum.DEVICE_ACCESS_GRANTED;
          this._initVideoAudio();
        },

        _initAudioContext: function() {
          window.AudioContext = window.AudioContext || window.webkitAudioContext;

          if (!window.AudioContext) {
            alert('AudioContext API is NOT supported in your browser :(');
            return;
          }

          this._audioContext = new AudioContext();

          // taken from http://www.webaudiodemos.appspot.com/AudioRecorder/js/main.js
          this._inputPoint = this._audioContext.createGain();

          // Create an AudioNode from the stream.
          this._audioInput = this._audioContext.createMediaStreamSource(this._stream);
          this._audioInput.connect(this._inputPoint);

          this._audioRecorder = new Recorder(this._inputPoint, {
            workerPath: '/bower_components/Recorderjs/recorderWorker.js'
          });

          // mute the gain level to not loop the microphone input back to the speakers
          var zeroGain = this._audioContext.createGain();
          zeroGain.gain.value = 0.0;
          this._inputPoint.connect(zeroGain);
          zeroGain.connect(this._audioContext.destination);
        },

        _initVideoAudio: function() {
          this._currentUIState = this._uiStateEnum.DEVICE_ACCESS_GRANTED;

          // we must short delay to catch the DOM changes ...
          this.job('waitForDOM', function() {
            var liveVideo = this._shortSelect('#liveVideo');

            // show live video
            liveVideo.src = window.URL.createObjectURL(this._stream);
            liveVideo.play();
          });

          // init Audio
          this._initAudioContext();
        },

        _initGetUserMedia: function() {
          var videoDim = {
            width: 640,
            height: 480
          };

          if (this._viewport.width < 640 + 320 || this._viewport.height < 480 + 240) {
            videoDim.width = 320;
            videoDim.height = 240;
          }

          this._videoCanvas.width = videoDim.width * 2;
          this._videoCanvas.height = videoDim.height * 2;

          navigator.getUserMedia = (
            navigator.getUserMedia ||
            navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia ||
            navigator.msGetUserMedia
          );

          if (navigator.getUserMedia) {
            // see https://developer.mozilla.org/en-US/docs/NavigatorUserMedia.getUserMedia
            navigator.getUserMedia (

              // constraints
              {
                video: {
                  mandatory: {
                    minWidth: videoDim.width,
                    minHeight: videoDim.height
                  }
                },
                audio: {
                  mandatory: {
                    googEchoCancellation: false,
                    googAutoGainControl: false,
                    googNoiseSuppression: false,
                    googHighpassFilter: false
                  },
                  optional: []
                }
              },

              // successCallback
              (function(stream) {
                this._stream = stream;

                this._initVideoAudio();
              }).bind(this),

              // errorCallback
              function(err) {
                console.log("The following error occured: " + err);
              }
            );
          } else {
            alert('getUserMedia API is NOT supported in your browser :(');
          }
        }
      });

    })();
  </script>
</polymer-element>
